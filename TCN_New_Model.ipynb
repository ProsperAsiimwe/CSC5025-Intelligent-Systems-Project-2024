{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5380e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23381cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('JSE_clean_truncated.csv')\n",
    "\n",
    "# Define horizons and input windows\n",
    "horizons = [1, 2, 5, 10, 30]\n",
    "input_windows = [30, 60, 120]\n",
    "\n",
    "# Device configuration (GPU/CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TCN, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(len(num_channels) - 1):\n",
    "            layers.append(nn.Conv1d(in_channels=num_channels[i], out_channels=num_channels[i+1], kernel_size=kernel_size, dilation=2**i))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        \n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.output_layer = nn.Linear(num_channels[-1], output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.tcn(x)\n",
    "        x = x[:, :, -1]  # Get the last output\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c88779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sliding window input-output pairs\n",
    "def create_sequences(data, window_size, horizon):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - window_size - horizon):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size:i+window_size+horizon])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cacba878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, optimizer, num_epochs=100):\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e17362aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Evaluation function\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test).cpu().numpy()\n",
    "        y_test = y_test.cpu().numpy()\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "        return float(mae), float(mape), float(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36122de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search function\n",
    "def grid_search(company_idx, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, horizon):\n",
    "    best_rmse = float('inf')\n",
    "    best_params = {}\n",
    "    \n",
    "    # Hyperparameters to search\n",
    "    kernel_sizes = [2, 3]\n",
    "    num_channels_list = [[1, 16, 32], [1, 32, 64]]\n",
    "    dilation_factors = [1, 2]\n",
    "\n",
    "    for kernel_size in kernel_sizes:\n",
    "        for num_channels in num_channels_list:\n",
    "            for dilation in dilation_factors:\n",
    "                # Initialize the model\n",
    "                model = TCN(input_dim=1, output_dim=horizon, num_channels=num_channels, \n",
    "                            kernel_size=kernel_size).to(device)\n",
    "                \n",
    "                # Define the optimizer\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "                # Start time tracking\n",
    "                start_time = time.time()\n",
    "\n",
    "                # Train the model\n",
    "                train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "                train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "                train_model(model, train_loader, optimizer)\n",
    "\n",
    "                # End time tracking\n",
    "                end_time = time.time()\n",
    "                training_time = end_time - start_time\n",
    "                \n",
    "                # Evaluate the model\n",
    "                mae, mape, rmse = evaluate_model(model, X_test_tensor, y_test_tensor)\n",
    "                \n",
    "                # Track the best performance\n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse = rmse\n",
    "                    best_params = {\n",
    "                        'kernel_size': kernel_size,\n",
    "                        'num_channels': num_channels,\n",
    "                        'dilation': dilation,\n",
    "                        'mae': mae,\n",
    "                        'mape': mape,\n",
    "                        'rmse': rmse,\n",
    "                        'training_time': training_time\n",
    "                    }\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca6a0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a JSON file (append, don't overwrite)\n",
    "def save_results_to_json(result, file_name):\n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(file_name):\n",
    "        # If it exists, read the existing content\n",
    "        with open(file_name, \"r\") as f:\n",
    "            existing_data = json.load(f)\n",
    "    else:\n",
    "        # If it doesn't exist, create an empty list\n",
    "        existing_data = []\n",
    "\n",
    "    # Append the new result to the existing data\n",
    "    existing_data.append(result)\n",
    "\n",
    "    # Write back the updated data to the JSON file\n",
    "    with open(file_name, \"w\") as f:\n",
    "        json.dump(existing_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d41c9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for company 1\n",
      "\n",
      "--- Horizon: 1, Input Window: 30 ---\n",
      "\n",
      "Best Params for Company 1:\n",
      "{\n",
      "    \"company\": 1,\n",
      "    \"horizon\": 1,\n",
      "    \"input_window\": 30,\n",
      "    \"run_time\": 30.17138385772705,\n",
      "    \"mae\": 0.028898876160383224,\n",
      "    \"mape\": 4.514417424798012,\n",
      "    \"rmse\": 0.04118187353014946,\n",
      "    \"optimal_hyperparameters\": {\n",
      "        \"kernel_size\": 3,\n",
      "        \"num_channels\": [\n",
      "            1,\n",
      "            16,\n",
      "            32\n",
      "        ],\n",
      "        \"dilation\": 2\n",
      "    }\n",
      "}\n",
      "\n",
      "--- Horizon: 1, Input Window: 60 ---\n"
     ]
    }
   ],
   "source": [
    "for company_idx in range(data.shape[1]):\n",
    "    print(f\"\\nTraining for company {company_idx+1}\")\n",
    "    \n",
    "    # Extract data for the current company\n",
    "    company_data = data.iloc[:, company_idx].values\n",
    "\n",
    "    # Normalize the company data\n",
    "    company_data = (company_data - np.mean(company_data)) / np.std(company_data)\n",
    "\n",
    "    for horizon in horizons:\n",
    "        for input_window in input_windows:\n",
    "            print(f\"\\n--- Horizon: {horizon}, Input Window: {input_window} ---\")\n",
    "\n",
    "            # Create sequences for the current horizon and input window\n",
    "            X, y = create_sequences(company_data, input_window, horizon)\n",
    "\n",
    "            # Split the data into train and test sets (e.g., 80-20 split)\n",
    "            split_idx = int(0.8 * len(X))\n",
    "            X_train, y_train = X[:split_idx], y[:split_idx]\n",
    "            X_test, y_test = X[split_idx:], y[split_idx:]\n",
    "\n",
    "            # Convert data to PyTorch tensors\n",
    "            X_train_tensor = torch.Tensor(X_train).unsqueeze(1).to(device)  # Adding a channel dimension\n",
    "            y_train_tensor = torch.Tensor(y_train).to(device)\n",
    "            X_test_tensor = torch.Tensor(X_test).unsqueeze(1).to(device)\n",
    "            y_test_tensor = torch.Tensor(y_test).to(device)\n",
    "\n",
    "            # Perform grid search\n",
    "            best_params = grid_search(company_idx, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, horizon)\n",
    "\n",
    "            # Store and print results\n",
    "            result = {\n",
    "                \"company\": company_idx + 1,\n",
    "                \"horizon\": horizon,\n",
    "                \"input_window\": input_window,\n",
    "                \"run_time\": best_params[\"training_time\"],\n",
    "                \"mae\": best_params[\"mae\"],\n",
    "                \"mape\": best_params[\"mape\"],\n",
    "                \"rmse\": best_params[\"rmse\"],\n",
    "                \"optimal_hyperparameters\": {\n",
    "                    \"kernel_size\": best_params[\"kernel_size\"],\n",
    "                    \"num_channels\": best_params[\"num_channels\"],\n",
    "                    \"dilation\": best_params[\"dilation\"]\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Print best params\n",
    "            print(f\"\\nBest Params for Company {company_idx+1}:\")\n",
    "            print(json.dumps(result, indent=4))\n",
    "\n",
    "            # Save results to a JSON file (append instead of overwrite)\n",
    "            file_name = f\"company_{company_idx+1}.1_results.json\"\n",
    "            save_results_to_json(result, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31feade5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
